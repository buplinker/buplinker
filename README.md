# BUPLinker

BUPLinker is a tool designed to link User Reviews (UR) and Pull Requests (PR) to analyze the relationship between user feedback and software development activities.

---

## ðŸ’» Environment

- **OS**: macOS or Linux
- **Python**: 3.11
- **Git LFS**: Required for managing large files.
  ```bash
  brew install git-lfs && git lfs install
  ```
---
## âš™ï¸ Setup

### 1. Install Dependencies & Data

Run the following commands to download the necessary models, install libraries, and extract compressed results:

```shell
# Download FastText language identification model
curl -O https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin

# Install required Python packages
pip install -r requirements.txt
```

### 2. Configuration

* **GitHub**: Set your GitHub Auth Token in `project_config.py`.
* **OpenAI API**: Create a `.env` file in the root directory and add your key:
```text
OPENAI_API_KEY=your_api_key_here
```



---

## ðŸš€ How to Run BUPLinker

### Option A: Quick Start (Using Pre-prepared Data)

If you do not have a MySQL server, follow these steps:

#### 1. Extract Pre-computed Results

Extract the compressed output files:

```bash
tar xJf buplinker/code/output.tar.xz
tar xJf analysis/timeline/time_processed_data/all_years.tar.xz
tar xJf analysis/timeline/time_processed_data/limited_years.tar.xz
```

#### 2. Download Input Pairs Dataset

Download the `input_pairs` dataset from [Google Drive](https://drive.google.com/drive/folders/1eqfou_mbbqI0TqtCD8mk0l4BYTjavuxa?usp=drive_link).

#### 3. Place and Extract Dataset Files

Place the downloaded folder according to the [Project Structure](#-project-structure) and extract the compressed files:

```bash
tar xJf buplinker/dataset/input_pairs/ur_pr/all_years.tar.xz
tar xJf buplinker/dataset/input_pairs/ur_pr/limited_years.tar.xz
tar xJf buplinker/dataset/input_pairs/pr_ur/all_years.tar.xz
tar xJf buplinker/dataset/input_pairs/pr_ur/limited_years.tar.xz
```

#### 4. Proceed to Execution

Proceed directly to [Run BUPLinker Execution](#1-run-buplinker-execution).

### Option B: Full Pipeline (From Scratch)

If you want to fetch raw data and create your own tables, follow these steps:

> **Note**: It may take 2 or 3 days to fetch all data

#### 1. Set Your MySQL Server

Configure your MySQL credentials (URL, user name, password, and database name) in `project_config.py` if you have a MySQL server set up.

#### 2. Database & Data Fetching

```bash
# Create database tables
python3 data_fetch/database/tables.py

# Insert data from various sources
python3 data_fetch/repositories.py
python3 data_fetch/google_play_data.py
python3 data_fetch/github_data.py

```

#### 3. Preprocessing

Extract PR titles and templates for candidate selection:

```bash
python3 buplinker/dataset/preprocess/template_extractor.py

```

* Output: `buplinker/dataset/preprocess/template_title_repositories/*`

#### 4. Create Input Pairs

Filter candidate UR-PR pairs.

```bash
python3 buplinker/dataset/create_buplinker_input_pairs.py --limited

```

* `--limited`: Uses the first four years of data since the app's release.
* (Omit the flag to use all available data).

---

## ðŸ“Š Execution & Analysis

### 1. Run BUPLinker Execution

Apply the linking algorithm to the prepared input pairs:

```bash
bash ./buplinker/code/buplinker.sh

```

> **Note**: To switch between "limited" (4 years) and "all years", modify the `LIMITED` variable inside the `.sh` script.
> **Note**: Running BUPLinker for all repositories will cost around $150

### 2. Data Formatting for Analysis

If you have a MySQL server set up, format the output into timeline-friendly data.
Otherwise, skip this step:

```bash
python3 analysis/timeline/time_processed_data/create_timeline_data.py --limited

```

### 3. Run Analysis Metrics

Generate the final statistics for linked ratio and time:

| Task | Command | Output Directory |
| --- | --- | --- |
| **Analyze Linked Ratio** | `python3 analysis/timeline/linked_ratio.py --limited` | `analysis/timeline/results/linked_ratio/` |
| **Analyze Linked Time** | `python3 analysis/timeline/linked_time.py --limited` | `analysis/timeline/results/linked_time/` |

---

## ðŸ“˜ How to Evaluate BUPLinker

Execute BUPLinker to perform URâ†’PR and PRâ†’UR link prediction and evaluation based on the generated CSV files.

The predicted link results are saved as CSV/JSON files.  
Evaluation metrics (precision, recall, F1, etc.) are output to stdout and log files.

**Before running**, edit `buplinker/code/buplinker.sh` and set the following variables:

* `EVALUATION=true`: Enable evaluation mode (outputs evaluation metrics).
* `LIMITED=true`: Uses the first four years of data (limited_random).

Then run:

```bash
bash ./buplinker/code/buplinker.sh
```

* Output: `buplinker/code/output/{group_type}/limited_random/` or `buplinker/code/output/{group_type}/all_random/`

---

## ðŸ“‚ Project Structure

```
buplinker/
â”œâ”€â”€ buplinker/
â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”œâ”€â”€ buplinker.py          # Main BUPLinker execution script
â”‚   â”‚   â”œâ”€â”€ buplinker.sh          # Batch processing script
â”‚   â”‚   â”œâ”€â”€ util.py               # Utility functions
â”‚   â”‚   â”œâ”€â”€ prompts/              # LLM prompts for UR-PR and PR-UR linking
â”‚   â”‚   â””â”€â”€ output/               # BUPLinker execution results
â”‚   â””â”€â”€ dataset/
â”‚       â”œâ”€â”€ create_buplinker_input_pairs.py  # Generate candidate pairs
â”‚       â”œâ”€â”€ preprocess/
â”‚       â”‚   â”œâ”€â”€ template_extractor.py            # Extract PR/Issue templates
â”‚       â”‚   â”œâ”€â”€ preprocess_pr.py                 # Preprocess PR descriptions
â”‚       â”‚   â”œâ”€â”€ label_user_review.py             # Label user reviews with ARdoc
â”‚       â”‚   â”œâ”€â”€ label_repository.py              # Label repositories with categories
â”‚       â”‚   â”œâ”€â”€ groundtruthbots.csv              # List of bot-generated PRs used during preprocessing
â”‚       â”‚   â”œâ”€â”€ template_titles.csv              # Template title extraction results
â”‚       â”‚   â”œâ”€â”€ template_titles_repositories/    # Repository template titles (per repository)
â”‚       â”‚   â””â”€â”€ prompts/                         # LLM prompts for template extraction
â”‚       â””â”€â”€ input_pairs/                              # Input pair datasets
â”‚           â”œâ”€â”€ pr_ur/                                # PR â†’ UR candidate pairs
â”‚           â”‚   â”œâ”€â”€ limited_random_input_pairs.csv    # Evaluation results of randomly sampled data
â”‚           â”‚   â”œâ”€â”€ limited_years/                    # First 4 years of data
â”‚           â”‚   â””â”€â”€ all_years/                        # All available years
â”‚           â””â”€â”€ ur_pr/                                # UR â†’ PR candidate pairs
â”‚               â”œâ”€â”€ limited_random_input_pairs.csv    # Evaluation results of randomly sampled data
â”‚               â”œâ”€â”€ limited_years/                    # First 4 years of data
â”‚               â””â”€â”€ all_years/                        # All available years
â”œâ”€â”€ data_fetch/
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ tables.py             # Database schema definitions
â”‚   â”‚   â”œâ”€â”€ get.py                # Database read operations
â”‚   â”‚   â””â”€â”€ set.py                # Database write operations
â”‚   â”œâ”€â”€ github_data.py            # Fetch GitHub data (PRs, Issues, Releases)
â”‚   â”œâ”€â”€ google_play_data.py       # Fetch Google Play Store reviews
â”‚   â”œâ”€â”€ repositories.py           # Load repository data from CSV and add to database
â”‚   â”œâ”€â”€ template_fetcher.py       # Fetch PR/Issue templates from GitHub
â”‚   â”œâ”€â”€ query_templates/          # GraphQL query templates for GitHub API
â”‚   â”‚   â”œâ”€â”€ issues.graphql        # GraphQL query for fetching GitHub issues
â”‚   â”‚   â”œâ”€â”€ pullRequests.graphql  # GraphQL query for fetching GitHub pull requests
â”‚   â”‚   â””â”€â”€ releases.graphql      # GraphQL query for fetching GitHub releases
â”‚   â””â”€â”€ tables/ 
â”‚       â””â”€â”€ repositories.csv      # List of analyzed repositories                   
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ timeline/
â”‚       â”œâ”€â”€ linked_ratio.py              # Analyze linking ratio metrics
â”‚       â”œâ”€â”€ linked_time.py               # Analyze linking time metrics
â”‚       â”œâ”€â”€ base_plotter.py              # Base plotting utilities
â”‚       â”œâ”€â”€ statistics_analyzer.py       # Statistical analysis utilities
â”‚       â”œâ”€â”€ statistics_types.py          # Type definitions for statistics
â”‚       â”œâ”€â”€ time_processed_data/         # Formatted data for timeline analysis
â”‚       â”‚   â”œâ”€â”€ create_timeline_data.py  # Convert BUPLinker results to timeline format
â”‚       â”‚   â”œâ”€â”€ limited_years/           # Processed data for first 4 years
â”‚       â”‚   â””â”€â”€ all_years/               # Processed data for all years
â”‚       â””â”€â”€ results/                     # Analysis results and visualizations
â”‚           â”œâ”€â”€ linked_ratio/            # Linking ratio analysis results
â”‚           â””â”€â”€ linked_time/             # Linking time analysis results
â”œâ”€â”€ project_config.py             # Configuration file (GitHub token, MySQL settings)
â”œâ”€â”€ root_util.py                  # Root-level utility functions
â””â”€â”€ requirements.txt              # Python dependencies
```
